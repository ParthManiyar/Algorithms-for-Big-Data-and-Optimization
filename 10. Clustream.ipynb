{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters in the range:\n",
      "Cluster 1   Cluster Center(d dimension):   [67.0, 40.0]   Data points:  2\n",
      "Cluster 2   Cluster Center(d dimension):   [46.67, 53.67]   Data points:  3\n",
      "Cluster 3   Cluster Center(d dimension):   [43.0, 35.5]   Data points:  4\n",
      "Cluster 4   Cluster Center(d dimension):   [15.0, 57.25]   Data points:  4\n",
      "Cluster 5   Cluster Center(d dimension):   [56.9, 19.1]   Data points:  10\n",
      "Cluster 6   Cluster Center(d dimension):   [31.67, 59.44]   Data points:  9\n",
      "Cluster 7   Cluster Center(d dimension):   [24.75, 16.5]   Data points:  4\n",
      "Cluster 8   Cluster Center(d dimension):   [20.86, 36.71]   Data points:  7\n",
      "Cluster 9   Cluster Center(d dimension):   [63.8, 58.3]   Data points:  10\n",
      "Cluster 10   Cluster Center(d dimension):   [49.0, 69.0]   Data points:  1\n",
      "\n",
      "Final K clusters in range:\n",
      "Final Cluster 1   Cluster Center(d dimension):   [64.33, 55.25]   Data points:  12\n",
      "Final Cluster 2   Cluster Center(d dimension):   [31.41, 58.47]   Data points:  17\n",
      "Final Cluster 3   Cluster Center(d dimension):   [39.44, 26.24]   Data points:  25\n"
     ]
    }
   ],
   "source": [
    "#libaraies\n",
    "import uuid\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# used for snapshot intervals\n",
    "alpha = 2 \n",
    "\n",
    "# used to increase effectiveness of time horizon\n",
    "l = 2\n",
    "\n",
    "# dimensions of data\n",
    "d = 2 \n",
    "\n",
    "# max clusters stored \n",
    "q = 10 \n",
    "\n",
    "# initial time\n",
    "time = 1 \n",
    "\n",
    "# max duration of running stream\n",
    "maxtime = 100  \n",
    "\n",
    "# clusters dict, cluster[id] = cluster object \n",
    "clusters = {}\n",
    "\n",
    "# user defined number, helps in calculating least time stamp. i.e from last m timestamps\n",
    "m = 2\n",
    "\n",
    "# boundary when a cluster has only one data point \n",
    "fixed_boundary = 5\n",
    "\n",
    "# user defined number, for\n",
    "delta = 2\n",
    "\n",
    "# user defined number, multipled with rms of cluster to get boundary of the cluster\n",
    "T = 5\n",
    "\n",
    "# timestamps, ss[i] denotes a list of time of order i\n",
    "ss = []\n",
    "\n",
    "# clusters saved at times, ss_clusters[i] = clusters dict at time i\n",
    "ss_clusters = {}\n",
    "\n",
    "#randomnly creating an array o x and y corrodinate\n",
    "def online_data(): \n",
    "    \n",
    "    x = np.random.randint(10,70,(1,d))  \n",
    "    # convert to np.float32 \n",
    "    x = np.float32(x) \n",
    "    return x[0] \n",
    "\n",
    "# cluster class\n",
    "class cluster:\n",
    "    \n",
    "    # has unique id and 2d+3 elements\n",
    "    def __init__(self):\n",
    "        self.id = uuid.uuid1()\n",
    "        self.CF2x = [0]*d\n",
    "        self.CF1x = [0]*d\n",
    "        self.CF2t = 0\n",
    "        self.CF1t = 0\n",
    "        self.n = 0\n",
    "        \n",
    "    # to add a data point in cluster, uses additivity property\n",
    "    def add_point(self,val,time):\n",
    "        self.n += 1\n",
    "        for i in range(d):\n",
    "            self.CF2x[i] += (val[i])**2\n",
    "            self.CF1x[i] += (val[i])\n",
    "        self.CF2t += time**2\n",
    "        self.CF1t += time\n",
    "    \n",
    "    # delete a cluster, bascially remove it from the mainted clusters\n",
    "    def delete(self):\n",
    "        del clusters[self.id]\n",
    "    \n",
    "    # merge to a cluster, all its data is added to another one, additivity\n",
    "    def mergeto(self,c):\n",
    "        for i in range(d):\n",
    "            c.CF2x[i] += self.CF2x[i]\n",
    "            c.CF1x[i] += self.CF1x[i]\n",
    "        c.CF1t += self.CF1t\n",
    "        c.CF2t += self.CF2t\n",
    "        c.n += self.n\n",
    "    \n",
    "    # remove to a cluster, used to undo mergeto operation in queries as they are independent\n",
    "    def removeto(self,c):\n",
    "        for i in range(d):\n",
    "            c.CF2x[i] -= self.CF2x[i]\n",
    "            c.CF1x[i] -= self.CF1x[i]\n",
    "        c.CF1t -= self.CF1t\n",
    "        c.CF2t -= self.CF2t\n",
    "        c.n -= self.n\n",
    "        \n",
    "    # to find the centroid of the cluster with n data points\n",
    "    def centroid(self):\n",
    "        if(self.n==0):\n",
    "            return 0\n",
    "        arr = []\n",
    "        for i in range(d):\n",
    "            arr.append(self.CF1x[i]/self.n)\n",
    "        return arr\n",
    "    \n",
    "    # to find the timestamps centroid with n timestamps\n",
    "    def centroid_time(self):\n",
    "        if(self.n==0):\n",
    "            return 0\n",
    "        arr= self.CF1t/self.n\n",
    "        return arr\n",
    "    \n",
    "    # to find mean, just call centroid\n",
    "    def mean(self):\n",
    "        return self.centroid()\n",
    "    \n",
    "    # to find mean_time, just call centroid time\n",
    "    def mean_time(self):\n",
    "        return self.centroid_time()\n",
    "\n",
    "    # standard deviation of the data points of the cluster\n",
    "    def standard_deviation(self):\n",
    "        if(self.n==0):\n",
    "            return zero\n",
    "        if(self.n==1):\n",
    "            return fixed_boundary\n",
    "        centroid = self.centroid()\n",
    "        sum = 0\n",
    "        for i in range(d):\n",
    "            sum += self.CF2x[i]-2.0*centroid[i]*self.CF1x[i]+self.n*(centroid[i]**2)\n",
    "        sd = math.sqrt(sum/self.n)\n",
    "        return sd\n",
    "    \n",
    "    # standard deviation of the timestamps of the cluster\n",
    "    def standard_deviation_time(self):\n",
    "        if(self.n==0):\n",
    "            return zero\n",
    "        centroid = self.centroid_time()\n",
    "        sum1 = 0\n",
    "        sum1 = self.CF2t-2.0*centroid*self.CF1t+self.n*(centroid**2)\n",
    "        sd = math.sqrt(sum1/self.n)\n",
    "        return sd\n",
    "    \n",
    "# squaring of two points   \n",
    "def dist(x,y):\n",
    "    return (x-y)**2\n",
    "\n",
    "# finds the euclidean distance of 2 vectors of d dimensions,\n",
    "def dist_v(x,y):\n",
    "    sum = 0\n",
    "    for i in range(d):\n",
    "        sum += dist(x[i],y[i])\n",
    "    sum = math.sqrt(sum/d)\n",
    "    return sum\n",
    "\n",
    "# finds the nearest cluster object, in case of multiple, outputs last\n",
    "def find_nearest_cluster(x):\n",
    "    \n",
    "    mindist = math.inf\n",
    "    cluster_object = \"\"\n",
    "    \n",
    "    for id in clusters:\n",
    "        c = clusters[id]\n",
    "        centroid = c.centroid()\n",
    "        sum = dist_v(centroid,x)\n",
    "        mindist = min(mindist,sum)\n",
    "        if(mindist==sum):\n",
    "            cluster_object = c\n",
    "    return cluster_object\n",
    "\n",
    "# finds the cluster object with least timestamp among time of arrivals of (m/2n)th percentile of points\n",
    "def least_timestamp():\n",
    "    \n",
    "    minstamp = math.inf\n",
    "    cluster_object = \"\"\n",
    "    \n",
    "    for id in clusters:\n",
    "        c = clusters[id]\n",
    "        if(c.n<2*m):\n",
    "            stamp = c.mean_time()\n",
    "        else:\n",
    "            stamp = norm.ppf(m/(2.0*c.n))*c.standard_deviation_time()+c.mean_time()\n",
    "        minstamp = min(minstamp,stamp)\n",
    "        if(stamp == minstamp):\n",
    "            cluster_object = c\n",
    "            \n",
    "    return [cluster_object,minstamp]\n",
    "\n",
    "# finds the max boundry\n",
    "def find_max_boundry(id):\n",
    "    \n",
    "    c = clusters[id]\n",
    "    return T*c.standard_deviation()\n",
    "\n",
    "# merges two clusters which are nearest\n",
    "def merge_nearest():\n",
    "    \n",
    "    c1 = c2 = \"\"\n",
    "    mindist = math.inf\n",
    "    \n",
    "    for id in clusters:\n",
    "        for id1 in clusters:\n",
    "            if(id==id1):\n",
    "                continue\n",
    "            distance = dist_v(clusters[id].centroid(),clusters[id1].centroid())\n",
    "            mindist = min(distance,mindist)\n",
    "            if(mindist==distance):\n",
    "                c1 = clusters[id]\n",
    "                c2 = clusters[id1]\n",
    "    \n",
    "    # merges with the cluster with bigger points\n",
    "    if(c1.n > c2.n):\n",
    "        c2.mergeto(c1)\n",
    "        c2.delete()\n",
    "    else:\n",
    "        c1.mergeto(c2)\n",
    "        c1.delete()\n",
    "        \n",
    "# saves all the clusters at one instance of time, pyramidal time frame\n",
    "def snapshot():\n",
    "        \n",
    "    order = math.floor(math.log(time,2))\n",
    "    for i in range(order,-1,-1):\n",
    "        if(time%pow(2,i)==0):\n",
    "            if(len(ss)<=i):\n",
    "                ss.append([])\n",
    "            ss[i].append(time)\n",
    "            ss_clusters[time] = copy.deepcopy(clusters)\n",
    "            if(len(ss[i]) > pow(alpha,l)+1):\n",
    "                x = ss[i].pop(0)\n",
    "                del ss_clusters[x]\n",
    "            break\n",
    "\n",
    "# finds a element which is just less= than the operational element\n",
    "def just_smallest(temp_time):\n",
    "    \n",
    "    maxtime = 0\n",
    "    for time_itr in ss_clusters:\n",
    "        if(time_itr <= temp_time):\n",
    "            maxtime = max(maxtime,time_itr)\n",
    "        \n",
    "    return maxtime\n",
    "\n",
    "# finds a element which is just greater= than the operational element\n",
    "def just_biggest(temp_time):\n",
    "    \n",
    "    mintime = math.inf\n",
    "    for time_itr in ss_clusters:\n",
    "        if(time_itr >= temp_time):\n",
    "            mintime = min(mintime,time_itr)\n",
    "            \n",
    "    return mintime\n",
    "\n",
    "# finds a single centroid with given centroids and thier frequencies in d dimension\n",
    "def weighted_centroid(weighted_arr):\n",
    "    \n",
    "    sum = num_points = 0\n",
    "    mean = [0]*d\n",
    "    for pair in weighted_arr:\n",
    "        num_points += pair[1]\n",
    "    \n",
    "    for i in range(d):\n",
    "        sum = 0\n",
    "        for pair in weighted_arr:\n",
    "            sum += pair[0][i]*pair[1]\n",
    "        sum /= num_points\n",
    "        mean[i] = sum\n",
    "            \n",
    "    return [mean,num_points]\n",
    "\n",
    "# shows the result of the program\n",
    "def show_result(weighted_list,cluster_list):\n",
    "    \n",
    "    for i in range(len(weighted_list)):\n",
    "        for j in range(len(weighted_list[i][0])):\n",
    "            weighted_list[i][0][j] = round(weighted_list[i][0][j],2)\n",
    "            \n",
    "    for i in range(len(cluster_list)):\n",
    "        for j in range(len(cluster_list[i][0])):\n",
    "            cluster_list[i][0][j] = round(cluster_list[i][0][j],2)\n",
    "    \n",
    "    print(\"Clusters in the range:\")\n",
    "    for i in range(len(weighted_list)):\n",
    "        print(\"Cluster \"+str(i+1),\"  Cluster Center(d dimension):  \", str(weighted_list[i][0]),\"  Data points: \", str(weighted_list[i][1]))\n",
    "    print(\"\\nFinal K clusters in range:\")\n",
    "    for i in range(len(cluster_list)):\n",
    "        print(\"Final Cluster \"+str(i+1),\"  Cluster Center(d dimension):  \", str(cluster_list[i][0]),\"  Data points: \", str(cluster_list[i][1]))\n",
    "        \n",
    "# finds k clusters among the clusters in the range query\n",
    "def weighted_kmeans(k,weighted_list):\n",
    "    \n",
    "    itr = 100\n",
    "    cluster_list = []\n",
    "    for i in range(k):\n",
    "        temp_list = copy.deepcopy(weighted_list[i])\n",
    "        cluster_list.append(temp_list)\n",
    "    \n",
    "    while(itr > 0):\n",
    "        \n",
    "        itr -= 1\n",
    "        for i in range(k):\n",
    "            cluster_list[i][1] = 0\n",
    "            \n",
    "        weighted_arr = [[] for i in range(k)]\n",
    "        \n",
    "        for i in range(len(weighted_list)):\n",
    "            mindist = math.inf\n",
    "            ind = 0\n",
    "            for j in range(k):\n",
    "                distance = dist_v(weighted_list[i][0],cluster_list[j][0])\n",
    "                mindist = min(mindist,distance)\n",
    "                if(mindist==distance):\n",
    "                    ind = j\n",
    "            weighted_arr[ind].append(weighted_list[i])\n",
    "            \n",
    "        for i in range(k):\n",
    "            cluster_list[i] = weighted_centroid(weighted_arr[i])\n",
    "            \n",
    "    show_result(weighted_list,cluster_list)\n",
    "\n",
    "# query, k = desired clusters, t1 = timeframe 1, t2 = timeframe 2\n",
    "def query(k,t1,t2):\n",
    "    \n",
    "    if(t2 < t1):\n",
    "        print(\"t2 must br greater than t1!\")\n",
    "        return\n",
    "    if(k > q):\n",
    "        print(\"clusters must be less than q\")\n",
    "        return\n",
    "    \n",
    "    t1 = just_smallest(t1)\n",
    "    \n",
    "    if(t1==0):\n",
    "        print(\"t1 too low!\")\n",
    "        return  \n",
    "        \n",
    "    t2 = just_biggest(t2)\n",
    "    \n",
    "    if(t2==math.inf):\n",
    "        print(\"t2 too high!\")\n",
    "        return\n",
    "    \n",
    "    # use the subtractive properites of cluster\n",
    "    for id in ss_clusters[t2]:\n",
    "        if(id in ss_clusters[t1]):\n",
    "            ss_clusters[t1][id].removeto(ss_clusters[t2][id])\n",
    "    \n",
    "    weighted_list = []\n",
    "    for id in ss_clusters[t2]:\n",
    "        temp_list = []\n",
    "        temp_list.append(ss_clusters[t2][id].centroid())\n",
    "        temp_list.append(ss_clusters[t2][id].n)\n",
    "        if(temp_list[1]==0):\n",
    "            continue\n",
    "        weighted_list.append(temp_list)\n",
    "    \n",
    "    if(len(weighted_list) < k):\n",
    "        print(\"Less than K clusters! Select more wider range\")\n",
    "        return\n",
    "    \n",
    "    weighted_kmeans(k,weighted_list)\n",
    "    \n",
    "    # add those removed values again, for next queries\n",
    "    for id in ss_clusters[t2]:\n",
    "        if(id in ss_clusters[t1]):\n",
    "            ss_clusters[t1][id].mergeto(ss_clusters[t2][id])\n",
    "        \n",
    "# simply, making a new cluster for each data point till q\n",
    "def init_with_kmeans():  \n",
    "    \n",
    "    global time\n",
    "    \n",
    "    while(time < maxtime and len(clusters)  < q):\n",
    "\n",
    "        x = online_data()\n",
    "        c = cluster()\n",
    "        c.add_point(x,time)\n",
    "        clusters[c.id] = c\n",
    "\n",
    "        snapshot()\n",
    "        time += 1\n",
    "\n",
    "# main online algorithm \n",
    "def clustream():\n",
    "    \n",
    "    global time\n",
    "    \n",
    "    while(time < maxtime):\n",
    "\n",
    "        # gets the online data\n",
    "        x = online_data()\n",
    "        # finds the nearest cluster\n",
    "        M = find_nearest_cluster(x)\n",
    "        # finds the boundary point of the nearest cluster\n",
    "        b = find_max_boundry(M.id)\n",
    "        \n",
    "        # check if data point lies inside the boundary\n",
    "        if(dist_v(x,M.centroid())<=b):\n",
    "            # add the point to the cluster\n",
    "            M.add_point(x,time)\n",
    "        else:\n",
    "            # create new cluster and add data point and add it to clusters(dict)\n",
    "            c = cluster()\n",
    "            clusters[c.id] = c\n",
    "            c.add_point(x,time)\n",
    "            # calculate least timestamp cluster\n",
    "            cl = least_timestamp()\n",
    "            \n",
    "            # timestamp condition\n",
    "            if(cl[1] < delta):\n",
    "                # delete the least relevent cluster\n",
    "                cl[0].delete()\n",
    "            else:\n",
    "                # merge two nearest clusters\n",
    "                merge_nearest()\n",
    "        \n",
    "        # save the clusters\n",
    "        snapshot()\n",
    "        time += 1\n",
    "        \n",
    "        \n",
    "init_with_kmeans()\n",
    "\n",
    "clustream()\n",
    "    \n",
    "# k,t1,t2\n",
    "query(3,50,99)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
