{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Hoeffding Tree and VFDT\n",
    "\n",
    "### We have used bank dataset to test our implementation (https://www.kaggle.com/janiobachmann/bank-marketing-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and target:  Index(['job', 'marital', 'education', 'housing', 'loan', 'contact', 'campaign',\n",
      "       'poutcome'],\n",
      "      dtype='object')\n",
      "Number of training samples in stream:  4068\n",
      "Number of testing samples:  453\n",
      "    At sample 100 with epsilon 0.2838846213777555\n",
      "    Node-> 1, Parent id->0, Split Feature: loan,  height: 1 splitted\n",
      "    into 2 childs\n",
      "\n",
      "       At sample 215 with epsilon 0.2838846213777555\n",
      "       Node-> 2, Parent id->1, Split Feature: poutcome,  height: 2 splitted\n",
      "       into 4 childs\n",
      "\n",
      "       At sample 803 with epsilon 0.2838846213777555\n",
      "       Node-> 3, Parent id->1, Split Feature: poutcome,  height: 2 splitted\n",
      "       into 4 childs\n",
      "\n",
      "          At sample 807 with epsilon 0.14194231068887775\n",
      "          Node-> 6, Parent id->2, Split Feature: housing,  height: 3 splitted\n",
      "          into 2 childs\n",
      "\n",
      "          At sample 1284 with epsilon 0.2838846213777555\n",
      "          Node-> 7, Parent id->2, Split Feature: contact,  height: 3 splitted\n",
      "          into 2 childs\n",
      "\n",
      "             At sample 2350 with epsilon 0.12695706223349026\n",
      "             Node-> 12, Parent id->6, Split Feature: contact,  height: 4 splitted\n",
      "             into 3 childs\n",
      "\n",
      "             At sample 2394 with epsilon 0.2838846213777555\n",
      "             Node-> 14, Parent id->7, Split Feature: housing,  height: 4 splitted\n",
      "             into 2 childs\n",
      "\n",
      "             At sample 3189 with epsilon 0.0946282071259185\n",
      "             Node-> 13, Parent id->6, Split Feature: contact,  height: 4 splitted\n",
      "             into 3 childs\n",
      "\n",
      "          At sample 3878 with epsilon 0.2838846213777555\n",
      "          Node-> 5, Parent id->2, Split Feature: contact,  height: 3 splitted\n",
      "          into 3 childs\n",
      "\n",
      "As the training dataset has approx 4000 entries, it is not possible to split \n",
      "the features having high number of unique values, \n",
      "as epsilon requires around 10000 entries to reach acceptable value (around 0.03)\n",
      "\n",
      "The accuracy on the test set is: 78.57884374440688\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain, combinations\n",
    "from random import randrange as rr\n",
    "import math as m\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_csv('bank.csv')\n",
    "temp = np.array(dataset)\n",
    "\n",
    "# splitting the dataset\n",
    "x_train,x_test,y_train,y_test = train_test_split(temp[:,:-1],temp[:,-1],test_size=0.1,random_state=42)\n",
    "\n",
    "# list of feature names and it's column number\n",
    "feature_names = dataset.columns[:-1]\n",
    "feature_index = {}\n",
    "\n",
    "for i in range(len(feature_names)):\n",
    "    feature_index[feature_names[i]] = i \n",
    "\n",
    "# minimum samples required to check for splitting condition\n",
    "n_min   = 100\n",
    "           \n",
    "print(\"Features and target: \",feature_names)\n",
    "print(\"Number of training samples in stream: \", len(x_train))\n",
    "print(\"Number of testing samples: \", len(x_test))\n",
    "\n",
    "# node class stores the required data and sufficient statistics of each node\n",
    "class Node:\n",
    "    def __init__(self, height = 0, index=0):\n",
    "        self.feature_val = 'Leaf'\n",
    "        self.split_feature = 'Leaf'\n",
    "        self.childs = []\n",
    "        self.height = height\n",
    "        self.uni_class = set()\n",
    "        self.index = index\n",
    "        self.nl = 0\n",
    "        self.used_features = set()\n",
    "        self.x_train = []\n",
    "        self.y_train = []\n",
    "        self.parent = 0\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Node-> \"+str(self.index)+\", Parent id->\"+str(self.parent)+\", Split Feature: \"+ str(self.split_feature)+\",  height: \"+str(self.height)\n",
    "            \n",
    "root = Node(height=1,index=1)\n",
    "\n",
    "# print(root)\n",
    "# function to calculate information of a target variable\n",
    "def info(target_list):\n",
    "    \n",
    "    # to avoid runtime error in case of a splitinfo \n",
    "    # of an attribute with all same values\n",
    "    i=0.000000001\n",
    "    uni_vals = set(target_list)\n",
    "    \n",
    "    for ele in uni_vals:\n",
    "        p = target_list.count(ele)/len(target_list)\n",
    "        i -= p*m.log2(p)\n",
    "    return i\n",
    "\n",
    "# function to find information of a feature column\n",
    "def info_feature(x,y):\n",
    "    \n",
    "    info_f = 0\n",
    "    uni_features = set(x)\n",
    "\n",
    "    temp = {}\n",
    "    \n",
    "    for ele in uni_features:\n",
    "        temp[ele] = []\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        temp[x[i]].append(y[i])\n",
    "        \n",
    "    for ele in uni_features:\n",
    "        d = len(temp[ele])/len(x)\n",
    "        info_f -= d*info(temp[ele])\n",
    "        \n",
    "    return info_f\n",
    "\n",
    "n_count = 0\n",
    "index=2\n",
    "uni_class = set()\n",
    "n2=0\n",
    "\n",
    "# parameters of Hoeffding Tree\n",
    "delta = 0.0000001\n",
    "e = 0\n",
    "t = 0.1\n",
    "\n",
    "# function to generate stream data from training set\n",
    "def StreamGenerator():\n",
    "\n",
    "# the function iterates through the training set and yields one entry each time\n",
    "    for i in range(len(x_train)):\n",
    "\n",
    "        yield(x_train[i],y_train[i])\n",
    "\n",
    "stream = StreamGenerator()\n",
    "\n",
    "# start reading the stream\n",
    "for x,y in stream:\n",
    "    \n",
    "    n_count+=1\n",
    "    node = root\n",
    "    \n",
    "    # find the suitable node for current data point\n",
    "    while (node.split_feature!='Leaf'):\n",
    "        ind = feature_index[node.split_feature]\n",
    "        \n",
    "        flag=1\n",
    "        for c in node.childs:\n",
    "            i+=1\n",
    "            if c.feature_val == x[ind]:\n",
    "                node = c\n",
    "                flag=0\n",
    "            # print(c.feature_val,x[ind])\n",
    "        # print(node)\n",
    "        if flag==1:\n",
    "            nn = Node(height=node.height+1, index = index)\n",
    "            nn.feature_val=x[ind]\n",
    "            nn.parent = node.index\n",
    "            nn.used_features = node.used_features.copy()\n",
    "            index+=1\n",
    "            node.childs.append(nn)\n",
    "            \n",
    "    # update the node data \n",
    "    node.nl+=1\n",
    "    node.uni_class.add(y)\n",
    "    node.x_train.append(x)\n",
    "    node.y_train.append(y)\n",
    "    \n",
    "    # condition one of the algorithm\n",
    "    if (node.nl % n_min == 0) and len(node.uni_class)>0:\n",
    "        \n",
    "        r1=0\n",
    "        r2=0\n",
    "        f1='None'\n",
    "        f2='None'\n",
    "        info_y = info(node.y_train)\n",
    "        f_col = []\n",
    "        \n",
    "        # find a feature which is not yet used in the current branch\n",
    "        # find the max 2 gain ratio among those features\n",
    "        for f_name in feature_names:\n",
    "            if f_name not in node.used_features:\n",
    "                \n",
    "                ind = feature_index[f_name]\n",
    "#                 print(ind)\n",
    "                feature_col = [ele[ind] for ele in node.x_train]\n",
    "            \n",
    "                gain = info_y - info_feature(feature_col,node.y_train)\n",
    "                splitinfo = info(feature_col)\n",
    "             \n",
    "                gain_ratio = gain/splitinfo\n",
    "                \n",
    "                if gain_ratio > r1:\n",
    "                    r1,r2 = gain_ratio,r1\n",
    "                    f1,f2 = f_name,f1\n",
    "                    f_col = feature_col\n",
    "                elif gain_ratio > r2:\n",
    "                    r2 = gain_ratio\n",
    "                    f2 = f_name\n",
    "                \n",
    "        R = m.log2(len(node.uni_class))\n",
    "\n",
    "        # calculate epsilon\n",
    "        e = m.sqrt(R*R*m.log(1/delta)/(2*node.nl))\n",
    "\n",
    "        # 2nd condition of the algorithm\n",
    "        if f1 != 'None' and ((r1-r2)>e or e<t):\n",
    "            \n",
    "            # split the node into childs with unique values of the split features\n",
    "            \n",
    "            node.split_feature = f1\n",
    "\n",
    "            node.used_features.add(f1)\n",
    "            \n",
    "            feature_vals = set(f_col)\n",
    "            \n",
    "            for ele in feature_vals:\n",
    "                nn = Node(height=node.height+1, index = index)\n",
    "                nn.feature_val=ele\n",
    "                nn.parent = node.index\n",
    "                nn.used_features = node.used_features.copy()\n",
    "                index+=1\n",
    "                node.childs.append(nn)\n",
    "                \n",
    "            sep_string = (\"   \")*node.height\n",
    "            print(sep_string,\"At sample\",n_count,\"with epsilon\",e)\n",
    "            print(sep_string,node,\"splitted\")\n",
    "            print(sep_string,\"into\",len(node.childs),\"childs\\n\")\n",
    "            n2+=node.nl\n",
    "\n",
    "# predict function which gives accuracy \n",
    "def predict(x,y):\n",
    "\n",
    "    accuracy = 0\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        node = root\n",
    "        \n",
    "        # find the suitable node for current data point\n",
    "        while node.split_feature!='Leaf':\n",
    "            ind = feature_index[node.split_feature]\n",
    "            flag = 1\n",
    "            for c in node.childs:\n",
    "                if c.feature_val == x[i][ind]:\n",
    "                    node = c\n",
    "                    flag=0\n",
    "                break\n",
    "            if flag==1:\n",
    "                break\n",
    "        \n",
    "        score = node.y_train.count(y[i])/len(node.y_train)\n",
    "        accuracy += score\n",
    "        \n",
    "    accuracy = 100*accuracy/len(y)\n",
    "    print(\"The accuracy on the test set is:\",accuracy)\n",
    "    \n",
    "print(\"As the training dataset has approx 4000 entries, it is not possible to split \\nthe features having high number of unique values, \\nas epsilon requires around 10000 entries to reach acceptable value (around 0.03)\\n\")\n",
    "predict(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
