{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 6:\n",
    "### AU1741001: Akash Tike\n",
    "### AU1741011: Smit Mandavia\n",
    "### AU1741068: Parth Maniyar\n",
    "### AU1741095: Shaunak Vyas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression using Normal Equation Method : \n",
    "\n",
    "<img src=\"image1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train's shape : (404, 14)\n",
      "y_train's shape : (404,)\n",
      "X_test's shape : (102, 14)\n",
      "y_test's shape : (102,)\n",
      "Theta :  [ 3.00771669e+01 -2.02135297e-01  4.41276341e-02  5.26739364e-02\n",
      "  1.88474315e+00 -1.49281487e+01  4.76038673e+00  2.88734527e-03\n",
      " -1.30025278e+00  4.61661953e-01 -1.55434673e-02 -8.11632369e-01\n",
      " -1.97174433e-03 -5.32273431e-01]\n",
      "Shape of Theta (14,)\n",
      "MAE: 4.7300172509620095\n",
      "MSE: 32.79986268021572\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, metrics\n",
    "from numpy.linalg import inv, pinv, LinAlgError\n",
    "\n",
    "X, y = datasets.load_boston(return_X_y=True) # Loading Data from boston data set with X and y separate\n",
    "\n",
    "\n",
    "X  = np.append( np.ones([len(X),1]) ,X,axis=1) # Adding dummy column with all values one\n",
    "\n",
    "Split_ratio = 0.8  # Split ratio to split data into train and test data\n",
    "Split_index = int(len(X)*Split_ratio) # Index from which it will split\n",
    " \n",
    "#Splitiing data    \n",
    "X_train = X[0:Split_index] \n",
    "y_train = y[0:Split_index]\n",
    "\n",
    "print(\"X_train's shape :\" , X_train.shape)\n",
    "print(\"y_train's shape :\" , y_train.shape)\n",
    "\n",
    "X_test = X[Split_index:len(X)]\n",
    "y_test = y[Split_index:len(y)]\n",
    "\n",
    "print(\"X_test's shape :\" , X_test.shape)\n",
    "print(\"y_test's shape :\" , y_test.shape)\n",
    "\n",
    "# Finding theta using given equation\n",
    "try: \n",
    "    theta = inv( np.dot(X_train.T, X_train ))\n",
    "    theta = np.dot( theta, X_train.T )\n",
    "    theta = np.dot( theta, y_train)    \n",
    "except LinAlgError: # if inverse do not exist use psuedo inverse\n",
    "    theta = pinv( np.dot(X_train.T, X_train ))\n",
    "    theta = np.dot( theta, X_train.T )\n",
    "    theta = np.dot( theta, y_train)    \n",
    "    \n",
    "print(\"Theta : \", theta)\n",
    "print(\"Shape of Theta\", theta.shape)   \n",
    "\n",
    "predictions=np.dot(theta,X_test.T)  # Finding predictions of test data using theta\n",
    "\n",
    "print(\"MAE:\", metrics.mean_absolute_error(y_true=y_test,y_pred=predictions)) # Finding mean absolute error\n",
    "print(\"MSE:\", metrics.mean_squared_error(y_true=y_test,y_pred=predictions))  # Finding mean squared error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Regression for Streaming Data (using Stochastic Gradient Descent)\n",
    "works as a linear regression when number of features is one in dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries section\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets,metrics\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x,y:  (506, 14) (506,)\n",
      "Shape of x_train, y_train:  (404, 14) (404,)\n",
      "Shape of x_test, y_test:  (102, 14) (102,)\n"
     ]
    }
   ],
   "source": [
    "# reading the dataset\n",
    "\n",
    "# train test splitting ratio\n",
    "split_ratio = 0.8\n",
    "\n",
    "x,y = datasets.load_boston(return_X_y = True)\n",
    "\n",
    "# adding dummy feature to the dependent variable matrix\n",
    "x = np.append(np.ones([len(x),1]),x,axis=1)\n",
    "\n",
    "# x is now feature matrix with dummy variable\n",
    "print(\"Shape of x,y: \",x.shape,y.shape)\n",
    "\n",
    "# splitting into training and testing\n",
    "x_train = x[:int(split_ratio*x.shape[0])]\n",
    "y_train = y[:int(split_ratio*x.shape[0])]\n",
    "\n",
    "x_test  = x[int(split_ratio*x.shape[0]):]\n",
    "y_test  = y[int(split_ratio*x.shape[0]):]\n",
    "\n",
    "print(\"Shape of x_train, y_train: \",x_train.shape,y_train.shape)\n",
    "print(\"Shape of x_test, y_test: \",x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of data\n",
    "# as different ranges results into nan error in gradient descent in some cases\n",
    "\n",
    "# cretes an object of StandardScaler\n",
    "standard_scaler=StandardScaler()\n",
    "standard_scaler.fit(x_train[:,1:])\n",
    "\n",
    "# we should not normalize the first column, as it is just dummy variable\n",
    "x_train[:,1:]= standard_scaler.transform(x_train[:,1:])\n",
    "x_test[:,1:] = standard_scaler.transform(x_test[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate stream data from training set\n",
    "def StreamGenerator():\n",
    "\n",
    "# the function iterates through the training set and yields one entry each time\n",
    "    for i in range(x_train.shape[0]):\n",
    "        yield(x_train[i],y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model through stream\n",
    "\n",
    "stream = StreamGenerator()\n",
    "\n",
    "# number of thetas = number of features\n",
    "theta  = np.random.uniform(0,1,size=(x_train.shape[1]))\n",
    "\n",
    "#learning rate\n",
    "alpha = 0.01\n",
    "\n",
    "# here x,y is an entry of training set, received through stream\n",
    "for (x,y) in stream:\n",
    "    \n",
    "    # calculating h(x,theta) = x0*theta0 + x1*theta1 + ... + xn*thetan\n",
    "    y_pred = np.dot(x, theta)\n",
    "    \n",
    "    # error in predicted and actual value\n",
    "    err = y_pred - y\n",
    "\n",
    "    # gradient of error with respect to x\n",
    "    grad = err*x.T\n",
    "    \n",
    "    # updating the value of theta\n",
    "    theta = theta - alpha*grad   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  6.4208864504499505\n",
      "Mean Squared Error:  54.4115788973508\n"
     ]
    }
   ],
   "source": [
    "# testing the model with test dataset\n",
    "\n",
    "# predicting on test dataset\n",
    "y_pred = np.dot(x_test, theta)\n",
    "\n",
    "# calculating error metrics\n",
    "mae = metrics.mean_absolute_error(y_true = y_test, y_pred = y_pred)\n",
    "mse = metrics.mean_squared_error(y_true = y_test, y_pred = y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error: \", mae)\n",
    "print(\"Mean Squared Error: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple and Multiple Linear Regression using Gradient Descent (batch data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This is the generalized algorithm for multiple linear regression if number of attributes is equal to 1 then it is converted simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x,y:  (506, 14) (506,)\n",
      "Shape of x_train, y_train:  (404, 14) (404,)\n",
      "Shape of x_test, y_test:  (102, 14) (102,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# reading the datase and splitting into input and output variable\n",
    "\n",
    "# train test splitting ratio\n",
    "split_ratio = 0.8\n",
    "\n",
    "x,y = datasets.load_boston(return_X_y = True)\n",
    "\n",
    "# adding dummy feature to the dependent variable matrix\n",
    "x_temp = np.zeros((x.shape[0],x.shape[1]+1))\n",
    "x_temp[:,0] = np.ones((x_temp.shape[0]))\n",
    "x_temp[:,1:] = x\n",
    "x = x_temp\n",
    "\n",
    "# x is now feature matrix with dummy variable\n",
    "print(\"Shape of x,y: \",x.shape,y.shape)\n",
    "\n",
    "# splitting into training and testing\n",
    "x_train = x[:int(split_ratio*x.shape[0])]\n",
    "x_test  = x[int(split_ratio*x.shape[0]):]\n",
    "y_train = y[:int(split_ratio*x.shape[0])]\n",
    "y_test  = y[int(split_ratio*x.shape[0]):]\n",
    "\n",
    "print(\"Shape of x_train, y_train: \",x_train.shape,y_train.shape)\n",
    "print(\"Shape of x_test, y_test: \",x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling of input variable \n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_train[:,1:])\n",
    "x_train[:,1:]=scaler.transform(x_train[:,1:])\n",
    "x_test[:,1:]=scaler.transform(x_test[:,1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image for understanding and explanation purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of theta: <class 'numpy.ndarray'> Shape of Theta: (14,)\n",
      "Theta: [ 2.41747309e+01 -1.09931928e+00  8.74198106e-01 -2.40871635e-02\n",
      "  6.12968681e-01 -1.23949660e+00  3.63987990e+00 -6.17872405e-04\n",
      " -2.53808433e+00  1.86958870e+00 -9.96710499e-01 -1.67564644e+00\n",
      "  2.97907673e-02 -3.59762191e+00]\n",
      "Mean Absolute Error: 4.335812804045984\n",
      "Mean Square Error: 28.03930801527921\n"
     ]
    }
   ],
   "source": [
    "m=x_train.shape[0]\n",
    "n=x_train.shape[1]\n",
    "\n",
    "#number of iterations as stoping criteraia \n",
    "niterations=1000\n",
    "alpha=0.01#learning rate\n",
    "\n",
    "\n",
    "#intializing theta randomly between 0 and 1\n",
    "theta=np.random.uniform(0,1,n)\n",
    "print(\"Type of theta:\", type(theta), \"Shape of Theta:\", theta.shape)\n",
    "\n",
    "#algorithm as shown above\n",
    "for i in range(niterations):\n",
    "    update=np.zeros(n)\n",
    "    error=np.dot(x_train,theta) - y_train #h(x(i))-y(i) \n",
    "    for j in range(n):\n",
    "        update[j]=np.sum(error*(x_train.T)[j])\n",
    "    theta = theta - ((1/m)*(alpha)*update)\n",
    "\n",
    "    \n",
    "print(\"Theta:\",theta)\n",
    "\n",
    "predictions=np.dot(x_test, theta) #The Equation implemented as shown above\n",
    "\n",
    "print(\"Mean Absolute Error:\", metrics.mean_absolute_error(y_test,predictions))\n",
    "print(\"Mean Square Error:\", metrics.mean_squared_error(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Mathematical Stream Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries section\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from numpy.linalg import inv, pinv, LinAlgError\n",
    "from sklearn import metrics\n",
    "import math    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x,y:  (506, 14) (506,)\n",
      "Shape of x_train, y_train:  (404, 14) (404,)\n",
      "Shape of x_test, y_test:  (102, 14) (102,)\n"
     ]
    }
   ],
   "source": [
    "# reading the dataset\n",
    "\n",
    "# train test splitting ratio\n",
    "split_ratio = 0.8\n",
    "\n",
    "x,y = datasets.load_boston(return_X_y = True)\n",
    "\n",
    "# adding dummy feature to the dependent variable matrix\n",
    "x = np.append(np.ones([len(x),1]),x,axis=1)\n",
    "\n",
    "# x is now feature matrix with dummy variable\n",
    "print(\"Shape of x,y: \",x.shape,y.shape)\n",
    "\n",
    "# splitting into training and testing\n",
    "x_train = x[:int(split_ratio*x.shape[0])]\n",
    "y_train = y[:int(split_ratio*x.shape[0])]\n",
    "\n",
    "x_test  = x[int(split_ratio*x.shape[0]):]\n",
    "y_test  = y[int(split_ratio*x.shape[0]):]\n",
    "\n",
    "print(\"Shape of x_train, y_train: \",x_train.shape,y_train.shape)\n",
    "print(\"Shape of x_test, y_test: \",x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta:  [ 3.00771669e+01 -2.02135297e-01  4.41276341e-02  5.26739364e-02\n",
      "  1.88474315e+00 -1.49281487e+01  4.76038673e+00  2.88734527e-03\n",
      " -1.30025278e+00  4.61661953e-01 -1.55434673e-02 -8.11632369e-01\n",
      " -1.97174433e-03 -5.32273431e-01]\n",
      "\n",
      "Mean Absolute Error:  4.730017250961159\n",
      "Mean Squared Error:  32.79986268020979\n"
     ]
    }
   ],
   "source": [
    "# Incremental Mathematical Stream Regression\n",
    "\n",
    "# Initializing Synopsis\n",
    "M = np.zeros((x_test.shape[1],x_test.shape[1])) # p*p\n",
    "\n",
    "V = np.zeros(x_test.shape[1]) # p*1\n",
    "\n",
    "# Initializing Beta\n",
    "beta = np.zeros(x_test.shape[1]) # p*1\n",
    "\n",
    "# Taking Batch Size\n",
    "length = 101\n",
    "\n",
    "if(x_train.shape[0] % length != 0):\n",
    "    \n",
    "    print(\"INVALID LENGTH\")\n",
    "    print(\"PLEASE CHOOSE EXACT DIVISOR\")\n",
    "else:\n",
    "    times = int(x_train.shape[0]/length)\n",
    "\n",
    "    for i in range(times):\n",
    "\n",
    "        # Fetching Group Data\n",
    "        x = x_train[i*length:(i+1)*length,:]\n",
    "        y = y_train[i*length:(i+1)*length]\n",
    "\n",
    "        try:\n",
    "            xtx_m_inv = inv(M + np.dot(x.T,x)) #inverse of (M+xtx)\n",
    "        except LinAlgError:\n",
    "            xtx_m_inv = pinv(M + np.dot(x.T,x)) #pseudo inverse of (M+xtx)\n",
    "\n",
    "        #xty\n",
    "        xty = np.dot(x.T,y)\n",
    "\n",
    "        #(M+xtx)^-1(V+xty)\n",
    "        beta = np.dot(xtx_m_inv,(V + xty)) \n",
    "\n",
    "        #storing synopsis\n",
    "        M = M + np.dot(x.T,x) \n",
    "        V = V + xty\n",
    "\n",
    "    # testing the model with test dataset\n",
    "\n",
    "    # predicting on test dataset\n",
    "    y_pred = np.dot(x_test, beta)\n",
    "\n",
    "    # calculating error metrics\n",
    "    mae = metrics.mean_absolute_error(y_true = y_test, y_pred = y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true = y_test, y_pred = y_pred)\n",
    "\n",
    "    print(\"Beta: \", beta)\n",
    "    print(\"\")\n",
    "    print(\"Mean Absolute Error: \", mae)\n",
    "    print(\"Mean Squared Error: \", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Stream Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta:  [ 4.93733262e+01  5.16559721e-01  1.91759478e-02  9.12150224e-02\n",
      "  4.73439451e+00 -5.03142784e+01  2.98961900e+00  4.81040425e-03\n",
      " -1.02804698e+00  6.79530282e-01 -2.09793804e-02 -7.35755924e-01\n",
      "  9.27697627e-03 -4.93837863e-01]\n",
      "\n",
      "Mean Absolute Error:  6.3859733088487705\n",
      "Mean Squared Error:  89.28080048157986\n"
     ]
    }
   ],
   "source": [
    "# Approximate Stream Regression\n",
    "\n",
    "# Initializing Beta\n",
    "beta = np.zeros(x_test.shape[1]) # p*1\n",
    "\n",
    "# Taking Beta Previous as 0\n",
    "beta_previous = 0\n",
    "\n",
    "# Initializing Alpha\n",
    "alpha = 0.5\n",
    "\n",
    "# Taking Batch Size\n",
    "length = 101\n",
    "\n",
    "if(x_train.shape[0] % length != 0):\n",
    "    \n",
    "    print(\"INVALID LENGTH\")\n",
    "    print(\"PLEASE CHOOSE EXACT DIVISOR\")\n",
    "else:\n",
    "    times = int(x_train.shape[0]/length)\n",
    "\n",
    "    for i in range(times):\n",
    "\n",
    "        # Fetching Group Data\n",
    "        x = x_train[i*length:(i+1)*length,:]\n",
    "        y = y_train[i*length:(i+1)*length]\n",
    "\n",
    "        try:\n",
    "            xtx_inv = inv(np.dot(x.T,x)) #inverse of (xtx)\n",
    "        except LinAlgError:\n",
    "            xtx_inv = pinv(np.dot(x.T,x)) #pseudo inverse of (xtx)\n",
    "\n",
    "        #xty\n",
    "        xty = np.dot(x.T,y)\n",
    "\n",
    "        #(xtx)^-1(xty)\n",
    "        beta_current = np.dot(xtx_inv,xty)\n",
    "\n",
    "        # Calculating Beta\n",
    "        beta = (1-alpha)*beta_current + alpha*(beta_previous)\n",
    "\n",
    "        # Saving this Beta as Previous Beta\n",
    "        beta_previous = beta\n",
    "\n",
    "    # testing the model with test dataset\n",
    "\n",
    "    # predicting on test dataset\n",
    "    y_pred = np.dot(x_test, beta)\n",
    "\n",
    "    # calculating error metrics\n",
    "    mae = metrics.mean_absolute_error(y_true = y_test, y_pred = y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true = y_test, y_pred = y_pred)\n",
    "\n",
    "    print(\"Beta: \", beta)\n",
    "    print(\"\")\n",
    "    print(\"Mean Absolute Error: \", mae)\n",
    "    print(\"Mean Squared Error: \", mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
